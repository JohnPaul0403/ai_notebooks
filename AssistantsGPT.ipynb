{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7ab60a49f034186b57d87c3ed2d3569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "ProjecBot, asst_x824apYmRJibSkPy2wsTxBbE",
              "ChatBot , asst_onGM5DVw851gXCnww9WTbIzC"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Select an assistant:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_c3420c49efb649aba676856809d4bed1",
            "style": "IPY_MODEL_b2ce9b0fa04044b1a572d4f50ebabada"
          }
        },
        "c3420c49efb649aba676856809d4bed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ce9b0fa04044b1a572d4f50ebabada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnPaul0403/ai_notebooks/blob/main/AssistantsGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get a hands on Assistans API from OpenAI**\n",
        "This is a collaboratory notebook, for thoose people who are trying to get there first interactions with Assistants GPT.\n",
        "\n",
        ">*Get more information about [Assistants GPT and API](https://platform.openai.com/docs/assistants/overview).*\n",
        "\n",
        ">*Get more information about [pricing](https://openai.com/pricing).*"
      ],
      "metadata": {
        "id": "uvWh3auwu1y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step One:** Get the dependencies\n",
        "\n",
        "Just execute the following code to get all dependencies."
      ],
      "metadata": {
        "id": "NLKOEMpkwY6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_14ZaGf7Ba3j"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n",
        "import os\n",
        "import openai\n",
        "import time\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Two:** Get OpenAI API key\n",
        "\n",
        "Introduce the OpenAI key\n",
        "\n",
        ">If you do not have one, refere [here](https://platform.openai.com/api-keys)."
      ],
      "metadata": {
        "id": "gQa4yEwHwrW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "OPENAI_API_TOKEN = \"\"#@param {\"type\" : \"string\"}\n",
        "# OpenAI API Key\n",
        "api_key = os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN\n",
        "\n",
        "# Initialize the client\n",
        "client = openai.OpenAI()"
      ],
      "metadata": {
        "id": "NhF4cHg4CJkY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Three:** Creating the first model\n",
        "\n",
        "To create a model are neccessary some aspects. First, it is only mandatory to introduce a gpt model to create a new model, but the more specific you are the better. Second, down this text is a code with an example of file. As a user you can create as many file as needed to you model. Afterwards add this to the file_ids list.\n",
        "\n",
        ">*Refer to this [link](https://platform.openai.com/docs/assistants/tools/supported-files) for more information about files support.*"
      ],
      "metadata": {
        "id": "lHH7stODxLSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = client.files.create(file=open(\"example_file.txt\", \"rb\"),purpose='assistants')\n",
        "file2 = client.files.create(file=open(\"example_file.txt\", \"rb\"),purpose='assistants')"
      ],
      "metadata": {
        "id": "XN5B56xBij4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Create a new Assistant gpt model**\n",
        "\n",
        "Click in the button \"Show code\" to see the code. In the parameter \"file_ids\" you can add all the neccessary files. It only workd with the retrivial tool and, only for GPT-3.5-turbo-1106 and GPT-4-1106-preview."
      ],
      "metadata": {
        "id": "0eh3dTc_ui54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create an Assistant\n",
        "#@title\n",
        "model_name = \"\"#@param {\"type\" : \"string\"}\n",
        "instructions = \"\"#@param {\"type\" : \"string\"}\n",
        "gpt_model = \"\"#@param {\"type\" : \"string\"}\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=model_name,\n",
        "    instructions=instructions,\n",
        "    model=gpt_model,\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    file_ids=[file1.id, file2.id]#Here should be listed all your files\n",
        ")"
      ],
      "metadata": {
        "id": "QSxu1TKEDwJx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Four:** Get all your models\n",
        "\n",
        "After creating your first model you can retrieve it by executing the following line of code."
      ],
      "metadata": {
        "id": "Ziy9B9UK0C6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "assistant_object = client.beta.assistants.list()\n",
        "assistant_list = [f\"{assistant.name}, {assistant.id}\" for assistant in assistant_object]\n",
        "\n",
        "model_id_dropdown = widgets.Dropdown(\n",
        "    options=assistant_list,\n",
        "    value=assistant_list[0],\n",
        "    description=\"Select an assistant:\",\n",
        ")\n",
        "\n",
        "display(model_id_dropdown)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d7ab60a49f034186b57d87c3ed2d3569",
            "c3420c49efb649aba676856809d4bed1",
            "b2ce9b0fa04044b1a572d4f50ebabada"
          ]
        },
        "id": "nGIVw5CuoRQs",
        "outputId": "b1411ba5-991a-4b49-cd72-1477d5e7dfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Select an assistant:', options=('ProjecBot, asst_x824apYmRJibSkPy2wsTxBbE', 'ChatBot , aâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7ab60a49f034186b57d87c3ed2d3569"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Five:** Add a message\n",
        "\n",
        "After selecting the respective model, is now time to input a message for the model, *to do so just fill the message_conten input*"
      ],
      "metadata": {
        "id": "swNLjmvJ1vfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_id = model_id_dropdown.value.split(\", \")[1]\n",
        "\n",
        "# Create a Thread\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Add a Message to a Thread\n",
        "#@title\n",
        "message_content = \"\"#@param {\"type\" : \"string\"}\n",
        "\n",
        "message = client.beta.threads.messages.create(thread_id=thread.id,role=\"user\",\n",
        "    content=message_content\n",
        ")\n",
        "\n",
        "# Run the Assistant\n",
        "run = client.beta.threads.runs.create(thread_id=thread.id,assistant_id=assistant_id,instructions=\"Be specific and enthusiastic\")\n",
        "print(run.model_dump_json(indent=4))"
      ],
      "metadata": {
        "id": "oJbhgpoTEV-T",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Six:** Getting the message\n",
        "\n",
        "This code will fecth the reponse from the model and print all the information from the model. It will print for everutime the client connected to the model."
      ],
      "metadata": {
        "id": "BM9Kj3xK2KUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If run is 'completed', get messages and print\n",
        "while True:\n",
        "  # Retrieve the run status\n",
        "  run_status = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
        "  print(run_status.model_dump_json(indent=4))\n",
        "  if run_status.status == 'completed':\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    pprint(messages)\n",
        "    break\n",
        "  else:\n",
        "    ### sleep again\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "id": "mTrL-0mBEtUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Seven:** Just the message\n",
        "\n",
        "This line of code will output just the message from the model."
      ],
      "metadata": {
        "id": "H_uK7awD2ray"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(messages.data[0].content)"
      ],
      "metadata": {
        "id": "5mGvJC4Gi7Bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674e13da-3fa7-41a4-93c9-e854c86b2610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MessageContentText(text=Text(annotations=[], value='Tell about any file'), type='text')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ThreadMessage(id='msg_ncO30v2S4fKAZG5JXMaSdqB6', assistant_id='asst_onGM5DVw851gXCnww9WTbIzC', content=[MessageContentText(text=Text(annotations=[], value=\"It appears that I am unable to access the files you've uploaded because they are not compatible with the myfiles_browser tool I use to assist you. However, I can certainly help you with the files if you can provide more context or if you can upload a file format that is compatible with the tool, such as a text document, PDF, or an image with readable text. Please provide more information or upload another version of the file that can be accessed with the myfiles_browser tool, and I'll be more than happy to assist you with your needs!\"), type='text')], created_at=1703262206, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_KcURorSMUGbTSWQMQiC3Lx1n', thread_id='thread_HRHaI03hr6A1ztgYM2vIwQJR')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}